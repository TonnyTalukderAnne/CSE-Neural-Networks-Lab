{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "2B0I7hajuPOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is PyTorch?**\n",
        "\n",
        "PyTorch is an open-source deep learning framework developed by Facebook's AI Research lab (FAIR). It provides:\n",
        "\n",
        "* A flexible and dynamic tensor computation library (like NumPy but with GPU support)\n",
        "-- Tensor is 3D / 4D / n-D array.\n",
        "* An intuitive autograd system for automatic differentiation\n",
        "* A powerful module system (torch.nn) for building neural networks\n",
        "\n",
        "PyTorch is widely used in both research and industry due to its ease of use and strong support for dynamic computational graphs."
      ],
      "metadata": {
        "id": "yAHeFfV1uTt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perceptron"
      ],
      "metadata": {
        "id": "y3yR7WXa-OUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we will import the necessary PyTorch modules:\n",
        "\n",
        "* torch: for tensor operations and autograd\n",
        "* torch.nn: for building neural networks\n",
        "* torch.optim: for optimization algorithms like SGD\n",
        "\n",
        "These are core components in building and training neural networks in PyTorch.\n",
        "\n",
        "But what are tensors? Tensors are **multi-dimensional arrays** that generalize scalars, vectors, and matrices to higher dimensions. They are fundamental data structures used to represent and manipulate data in machine learning models, particularly in deep learning."
      ],
      "metadata": {
        "id": "v2gX2LzV-U1M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BI8GpbvNuHsY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define the input-output pairs for the AND gate, which is linearly separable:\n",
        "* Inputs: Two binary values\n",
        "* Output: 1 only if both inputs are 1, otherwise 0\n",
        "This dataset will be used to train a perceptron model from scratch."
      ],
      "metadata": {
        "id": "NkhCh2xf-eLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[0., 0.],\n",
        "                  [0., 1.],\n",
        "                  [1., 0.],\n",
        "                  [1., 1.]])\n",
        "y_true = torch.tensor([0., 0., 0., 1.])"
      ],
      "metadata": {
        "id": "f_rQ6IMX-Q-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We manually initialize the weights and bias of the Perceptron. Single perceptron does not need gradients"
      ],
      "metadata": {
        "id": "kYJHWMWu-7N9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.randn(2, requires_grad=False)\n",
        "b = torch.randn(1, requires_grad=False)\n",
        "'''\n",
        "# If you want to set the values manually\n",
        "w = torch.tensor([0., 0.], dtype=torch.float32, requires_grad=False)\n",
        "b = torch.tensor([0.], dtype=torch.float32, requires_grad=False)\n",
        "'''\n",
        "# Set learning rate\n",
        "lr = 0.1"
      ],
      "metadata": {
        "id": "oaHP5fIn-mU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this block, we train the perceptron using the **Perceptron Learning Rule**, a simple and intuitive way to update the weights based on classification errors.\n",
        "\n",
        "The key idea is:\n",
        "\n",
        "- For each input sample, compute the predicted label using a **step function** that outputs `1` or `-1`.\n",
        "- If the prediction is **correct**, do nothing.\n",
        "- If the prediction is **incorrect**, update the weights and bias using:\n",
        "\n",
        "$$\n",
        "\\mathbf{w} \\leftarrow \\mathbf{w} + \\eta \\cdot (y_{true}-y_{pred}) \\cdot \\mathbf{x}\n",
        "$$\n",
        "\n",
        "$$\n",
        "b \\leftarrow b + \\eta \\cdot (y_{true}-y_{pred})\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $ \\eta $ is the learning rate\n",
        "- $ y \\in \\{-1, 1\\} $ is the true label\n",
        "- $ \\mathbf{x} $ is the input vector\n",
        "\n",
        "This rule adjusts the decision boundary only when the model makes a mistake, helping the perceptron converge to a solution for **linearly separable problems** like the AND gate.\n",
        "\n",
        "We repeat this for multiple epochs and track the number of misclassified samples in each epoch. When misclassifications become zero, the perceptron has converged.\n"
      ],
      "metadata": {
        "id": "KK8G30U8_FBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(20):\n",
        "    errors = 0\n",
        "    for i in range(4):\n",
        "        xi = X[i]\n",
        "        yi = y_true[i]\n",
        "\n",
        "        z = torch.dot(w, xi) + b\n",
        "        prediction = 1.0 if z >= 0 else 0.0  # Step activation\n",
        "\n",
        "        # Only update if misclassified\n",
        "        if prediction != yi:\n",
        "            w += lr * (yi-prediction) * xi\n",
        "            b += lr * (yi-prediction)\n",
        "            errors += 1\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Misclassified: {errors}\")\n",
        "    if errors == 0:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dF81fnX_DKO",
        "outputId": "bcb651b4-4bbb-498e-e8dd-3044638b119f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Misclassified: 1\n",
            "Epoch 2, Misclassified: 2\n",
            "Epoch 3, Misclassified: 2\n",
            "Epoch 4, Misclassified: 3\n",
            "Epoch 5, Misclassified: 1\n",
            "Epoch 6, Misclassified: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we display the final weight and bias after all the updates and test the final perceptron model against our input."
      ],
      "metadata": {
        "id": "fcxznfDWBe4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final weights and bias\n",
        "print(\"\\nFinal weights:\", w)\n",
        "print(\"Final bias:\", b)\n",
        "\n",
        "# Test model\n",
        "print(\"\\nPredictions:\")\n",
        "for i in range(4):\n",
        "    xi = X[i]\n",
        "    z = torch.dot(w, xi) + b\n",
        "    prediction = 1.0 if z >= 0 else -1.0\n",
        "    print(f\"Input: {xi.tolist()}, Output: {prediction}, Target: {y_true[i].item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha1wlvOk_H4s",
        "outputId": "7a1fa8a8-347c-4e90-f322-b95ccd2da601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final weights: tensor([0.1144, 0.0634])\n",
            "Final bias: tensor([-0.1690])\n",
            "\n",
            "Predictions:\n",
            "Input: [0.0, 0.0], Output: -1.0, Target: 0.0\n",
            "Input: [0.0, 1.0], Output: -1.0, Target: 0.0\n",
            "Input: [1.0, 0.0], Output: -1.0, Target: 0.0\n",
            "Input: [1.0, 1.0], Output: 1.0, Target: 1.0\n"
          ]
        }
      ]
    }
  ]
}